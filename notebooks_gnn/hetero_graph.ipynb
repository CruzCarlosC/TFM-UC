{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu121\n"
     ]
    }
   ],
   "source": [
    "#Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import os\n",
    "\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "file_path = cwd + '/points_150.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>N_side</th>\n",
       "      <th>N_layer</th>\n",
       "      <th>t_label</th>\n",
       "      <th>phi</th>\n",
       "      <th>eta</th>\n",
       "      <th>q</th>\n",
       "      <th>pt</th>\n",
       "      <th>d0</th>\n",
       "      <th>z0</th>\n",
       "      <th>n_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.8856</td>\n",
       "      <td>-5.8159</td>\n",
       "      <td>-29.5959</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>T0</td>\n",
       "      <td>-0.8395</td>\n",
       "      <td>-2.1563</td>\n",
       "      <td>-1</td>\n",
       "      <td>54.6582</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.3150</td>\n",
       "      <td>-12.9382</td>\n",
       "      <td>-70.4852</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>T0</td>\n",
       "      <td>-0.8395</td>\n",
       "      <td>-2.1563</td>\n",
       "      <td>-1</td>\n",
       "      <td>54.6582</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.7589</td>\n",
       "      <td>-20.0473</td>\n",
       "      <td>-111.3745</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>T0</td>\n",
       "      <td>-0.8395</td>\n",
       "      <td>-2.1563</td>\n",
       "      <td>-1</td>\n",
       "      <td>54.6582</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.2174</td>\n",
       "      <td>-27.1433</td>\n",
       "      <td>-152.2638</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>T0</td>\n",
       "      <td>-0.8395</td>\n",
       "      <td>-2.1563</td>\n",
       "      <td>-1</td>\n",
       "      <td>54.6582</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1129</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.6903</td>\n",
       "      <td>-34.2260</td>\n",
       "      <td>-193.1531</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>T0</td>\n",
       "      <td>-0.8395</td>\n",
       "      <td>-2.1563</td>\n",
       "      <td>-1</td>\n",
       "      <td>54.6582</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1129</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x        y         z  N_side  N_layer t_label     phi     eta  q  \\\n",
       "0   7.8856  -5.8159  -29.5959      10        1      T0 -0.8395 -2.1563 -1   \n",
       "1  14.3150 -12.9382  -70.4852      10        2      T0 -0.8395 -2.1563 -1   \n",
       "2  20.7589 -20.0473 -111.3745      10        3      T0 -0.8395 -2.1563 -1   \n",
       "3  27.2174 -27.1433 -152.2638      10        4      T0 -0.8395 -2.1563 -1   \n",
       "4  33.6903 -34.2260 -193.1531      10        5      T0 -0.8395 -2.1563 -1   \n",
       "\n",
       "        pt      d0      z0  n_label  \n",
       "0  54.6582  0.0198  0.1129        0  \n",
       "1  54.6582  0.0198  0.1129        1  \n",
       "2  54.6582  0.0198  0.1129        2  \n",
       "3  54.6582  0.0198  0.1129        3  \n",
       "4  54.6582  0.0198  0.1129        4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(file_path)\n",
    "\n",
    "#Round the values of the dataset to 4 decimal places\n",
    "df = df.round(4)\n",
    "\n",
    "#Add a column to use as index from 0 to the length of the dataset\n",
    "df['n_label'] = range(0, len(df))\n",
    "\n",
    "#delete the column p_label\n",
    "df = df.drop('p_label', axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import HeteroData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empty hetero graph \n",
    "data=HeteroData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#node names\n",
    "nodes_s=df['n_label'].values\n",
    "nodes_t=df['n_label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add nodes to the graph\n",
    "data['source'].node_id = torch.tensor(nodes_s, dtype=torch.long)\n",
    "data['target'].node_id = torch.tensor(nodes_t, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add node attributes, in this case the position of the points\n",
    "data['source'].x = Tensor(df[['x', 'y', 'z']].values)\n",
    "data['target'].x = Tensor(df[['x', 'y', 'z']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  source={\n",
       "    node_id=[1500],\n",
       "    x=[1500, 3],\n",
       "  },\n",
       "  target={\n",
       "    node_id=[1500],\n",
       "    x=[1500, 3],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_path = cwd + '/grap_150.csv'\n",
    "\n",
    "# Importing the dataset\n",
    "df_edge = pd.read_csv(edge_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([df_edge['Source'], df_edge['Target']], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['source', 'weight', 'target'].edge_index = edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  source={\n",
       "    node_id=[1500],\n",
       "    x=[1500, 3],\n",
       "  },\n",
       "  target={\n",
       "    node_id=[1500],\n",
       "    x=[1500, 3],\n",
       "  },\n",
       "  (source, weight, target)={ edge_index=[2, 3538] }\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edge attributes\n",
    "weight_val = torch.from_numpy(df_edge['weight'].values).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['source', 'weight', 'target'].edge_label=weight_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  source={\n",
       "    node_id=[1500],\n",
       "    x=[1500, 3],\n",
       "  },\n",
       "  target={\n",
       "    node_id=[1500],\n",
       "    x=[1500, 3],\n",
       "  },\n",
       "  (source, weight, target)={\n",
       "    edge_index=[2, 3538],\n",
       "    edge_label=[3538],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if the data is valid\n",
    "data.validate(raise_on_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "data = T.ToUndirected()(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['target', 'rev_weight', 'source'].edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  source={\n",
       "    node_id=[1500],\n",
       "    x=[1500, 3],\n",
       "  },\n",
       "  target={\n",
       "    node_id=[1500],\n",
       "    x=[1500, 3],\n",
       "  },\n",
       "  (source, weight, target)={\n",
       "    edge_index=[2, 3538],\n",
       "    edge_label=[3538],\n",
       "  },\n",
       "  (target, rev_weight, source)={ edge_index=[2, 3538] }\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.validate(raise_on_error=True))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    neg_sampling_ratio=0.0,\n",
    "    edge_types=[('source', 'weight', 'target')],\n",
    "    rev_edge_types=[('target', 'rev_weight', 'source')],\n",
    ")(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  source={\n",
       "    node_id=[1500],\n",
       "    x=[1500, 3],\n",
       "  },\n",
       "  target={\n",
       "    node_id=[1500],\n",
       "    x=[1500, 3],\n",
       "  },\n",
       "  (source, weight, target)={\n",
       "    edge_index=[2, 2832],\n",
       "    edge_label=[2832],\n",
       "    edge_label_index=[2, 2832],\n",
       "  },\n",
       "  (target, rev_weight, source)={ edge_index=[2, 2832] }\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (encoder): GraphModule(\n",
      "    (conv1): ModuleDict(\n",
      "      (source__weight__target): SAGEConv((-1, -1), 32, aggr=mean)\n",
      "      (target__rev_weight__source): SAGEConv((-1, -1), 32, aggr=mean)\n",
      "    )\n",
      "    (conv2): ModuleDict(\n",
      "      (source__weight__target): SAGEConv((-1, -1), 32, aggr=mean)\n",
      "      (target__rev_weight__source): SAGEConv((-1, -1), 32, aggr=mean)\n",
      "    )\n",
      "  )\n",
      "  (decoder): EdgeDecoder(\n",
      "    (lin1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (lin2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = torch.nn.Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = torch.nn.Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        row, col = edge_label_index\n",
    "        z = torch.cat([z_dict['source'][row], z_dict['target'][col]], dim=-1)\n",
    "\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z)\n",
    "        return z.view(-1)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
    "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.decoder(z_dict, edge_label_index)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Model(hidden_channels=32).to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
    "                 train_data['source', 'target'].edge_label_index)\n",
    "    target = train_data['source', 'target'].edge_label\n",
    "    loss = F.mse_loss(pred, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    data = data.to(device)\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict,\n",
    "                 data['source', 'target'].edge_label_index)\n",
    "    pred = pred.clamp(min=0, max=1)\n",
    "    target = data['source', 'target'].edge_label.float()\n",
    "    rmse = F.mse_loss(pred, target).sqrt()\n",
    "    return float(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 40.8858, Train: 0.3504, Val: 0.3470\n",
      "Epoch: 002, Loss: 2009.2610, Train: 0.3513, Val: 0.3473\n",
      "Epoch: 003, Loss: 130.8028, Train: 0.6048, Val: 0.5859\n",
      "Epoch: 004, Loss: 23.6549, Train: 0.6895, Val: 0.6863\n",
      "Epoch: 005, Loss: 57.1019, Train: 0.7477, Val: 0.7165\n",
      "Epoch: 006, Loss: 35.2679, Train: 0.7408, Val: 0.7037\n",
      "Epoch: 007, Loss: 7.1158, Train: 0.6505, Val: 0.6468\n",
      "Epoch: 008, Loss: 1.1593, Train: 0.5736, Val: 0.5902\n",
      "Epoch: 009, Loss: 0.9359, Train: 0.5450, Val: 0.5651\n",
      "Epoch: 010, Loss: 1.3640, Train: 0.5247, Val: 0.5469\n",
      "Epoch: 011, Loss: 1.6383, Train: 0.5062, Val: 0.5310\n",
      "Epoch: 012, Loss: 1.6828, Train: 0.4883, Val: 0.5170\n",
      "Epoch: 013, Loss: 1.4607, Train: 0.4736, Val: 0.5049\n",
      "Epoch: 014, Loss: 1.0764, Train: 0.4675, Val: 0.5020\n",
      "Epoch: 015, Loss: 0.6886, Train: 0.4856, Val: 0.5150\n",
      "Epoch: 016, Loss: 0.5365, Train: 0.5080, Val: 0.5314\n",
      "Epoch: 017, Loss: 0.5937, Train: 0.5042, Val: 0.5017\n",
      "Epoch: 018, Loss: 0.5047, Train: 0.5317, Val: 0.5209\n",
      "Epoch: 019, Loss: 0.3476, Train: 0.5654, Val: 0.5470\n",
      "Epoch: 020, Loss: 0.3475, Train: 0.5862, Val: 0.5640\n",
      "Epoch: 021, Loss: 0.3588, Train: 0.5959, Val: 0.5699\n",
      "Epoch: 022, Loss: 0.3667, Train: 0.5919, Val: 0.5625\n",
      "Epoch: 023, Loss: 0.3639, Train: 0.5495, Val: 0.5207\n",
      "Epoch: 024, Loss: 0.3359, Train: 0.4894, Val: 0.4592\n",
      "Epoch: 025, Loss: 0.3918, Train: 0.5250, Val: 0.4899\n",
      "Epoch: 026, Loss: 0.3154, Train: 0.5382, Val: 0.4970\n",
      "Epoch: 027, Loss: 0.3216, Train: 0.4977, Val: 0.4789\n",
      "Epoch: 028, Loss: 0.3478, Train: 0.4889, Val: 0.4783\n",
      "Epoch: 029, Loss: 0.3545, Train: 0.5357, Val: 0.4955\n",
      "Epoch: 030, Loss: 0.3216, Train: 0.5517, Val: 0.5083\n",
      "Epoch: 031, Loss: 0.3164, Train: 0.5340, Val: 0.4941\n",
      "Epoch: 032, Loss: 0.2980, Train: 0.4815, Val: 0.4516\n",
      "Epoch: 033, Loss: 0.2627, Train: 0.4030, Val: 0.4069\n",
      "Epoch: 034, Loss: 0.2834, Train: 0.4026, Val: 0.4074\n",
      "Epoch: 035, Loss: 0.2564, Train: 0.4217, Val: 0.4260\n",
      "Epoch: 036, Loss: 0.2406, Train: 0.3914, Val: 0.4244\n",
      "Epoch: 037, Loss: 0.2250, Train: 0.3815, Val: 0.4224\n",
      "Epoch: 038, Loss: 0.2240, Train: 0.4409, Val: 0.4604\n",
      "Epoch: 039, Loss: 0.2222, Train: 0.4212, Val: 0.4540\n",
      "Epoch: 040, Loss: 0.2060, Train: 0.3887, Val: 0.4215\n",
      "Epoch: 041, Loss: 0.2258, Train: 0.4310, Val: 0.4596\n",
      "Epoch: 042, Loss: 0.2028, Train: 0.4217, Val: 0.4520\n",
      "Epoch: 043, Loss: 0.1950, Train: 0.3723, Val: 0.4039\n",
      "Epoch: 044, Loss: 0.1930, Train: 0.3728, Val: 0.4055\n",
      "Epoch: 045, Loss: 0.1734, Train: 0.3971, Val: 0.4247\n",
      "Epoch: 046, Loss: 0.1821, Train: 0.3691, Val: 0.3969\n",
      "Epoch: 047, Loss: 0.1670, Train: 0.3457, Val: 0.3703\n",
      "Epoch: 048, Loss: 0.1744, Train: 0.3568, Val: 0.3801\n",
      "Epoch: 049, Loss: 0.1568, Train: 0.3777, Val: 0.3946\n",
      "Epoch: 050, Loss: 0.1610, Train: 0.3567, Val: 0.3744\n",
      "Epoch: 051, Loss: 0.1488, Train: 0.3403, Val: 0.3527\n",
      "Epoch: 052, Loss: 0.1534, Train: 0.3472, Val: 0.3581\n",
      "Epoch: 053, Loss: 0.1427, Train: 0.3630, Val: 0.3695\n",
      "Epoch: 054, Loss: 0.1467, Train: 0.3406, Val: 0.3519\n",
      "Epoch: 055, Loss: 0.1399, Train: 0.3256, Val: 0.3386\n",
      "Epoch: 056, Loss: 0.1443, Train: 0.3385, Val: 0.3498\n",
      "Epoch: 057, Loss: 0.1356, Train: 0.3500, Val: 0.3588\n",
      "Epoch: 058, Loss: 0.1361, Train: 0.3337, Val: 0.3463\n",
      "Epoch: 059, Loss: 0.1297, Train: 0.3247, Val: 0.3386\n",
      "Epoch: 060, Loss: 0.1308, Train: 0.3293, Val: 0.3427\n",
      "Epoch: 061, Loss: 0.1251, Train: 0.3370, Val: 0.3490\n",
      "Epoch: 062, Loss: 0.1249, Train: 0.3279, Val: 0.3419\n",
      "Epoch: 063, Loss: 0.1212, Train: 0.3160, Val: 0.3326\n",
      "Epoch: 064, Loss: 0.1212, Train: 0.3162, Val: 0.3334\n",
      "Epoch: 065, Loss: 0.1198, Train: 0.3247, Val: 0.3413\n",
      "Epoch: 066, Loss: 0.1192, Train: 0.3255, Val: 0.3430\n",
      "Epoch: 067, Loss: 0.1189, Train: 0.3179, Val: 0.3384\n",
      "Epoch: 068, Loss: 0.1172, Train: 0.3157, Val: 0.3383\n",
      "Epoch: 069, Loss: 0.1179, Train: 0.3196, Val: 0.3421\n",
      "Epoch: 070, Loss: 0.1163, Train: 0.3253, Val: 0.3470\n",
      "Epoch: 071, Loss: 0.1169, Train: 0.3232, Val: 0.3461\n",
      "Epoch: 072, Loss: 0.1160, Train: 0.3174, Val: 0.3426\n",
      "Epoch: 073, Loss: 0.1155, Train: 0.3156, Val: 0.3411\n",
      "Epoch: 074, Loss: 0.1153, Train: 0.3181, Val: 0.3424\n",
      "Epoch: 075, Loss: 0.1140, Train: 0.3200, Val: 0.3434\n",
      "Epoch: 076, Loss: 0.1140, Train: 0.3156, Val: 0.3396\n",
      "Epoch: 077, Loss: 0.1129, Train: 0.3107, Val: 0.3356\n",
      "Epoch: 078, Loss: 0.1128, Train: 0.3107, Val: 0.3352\n",
      "Epoch: 079, Loss: 0.1119, Train: 0.3141, Val: 0.3377\n",
      "Epoch: 080, Loss: 0.1115, Train: 0.3137, Val: 0.3373\n",
      "Epoch: 081, Loss: 0.1110, Train: 0.3093, Val: 0.3340\n",
      "Epoch: 082, Loss: 0.1104, Train: 0.3078, Val: 0.3330\n",
      "Epoch: 083, Loss: 0.1102, Train: 0.3100, Val: 0.3345\n",
      "Epoch: 084, Loss: 0.1096, Train: 0.3112, Val: 0.3352\n",
      "Epoch: 085, Loss: 0.1095, Train: 0.3072, Val: 0.3320\n",
      "Epoch: 086, Loss: 0.1090, Train: 0.3050, Val: 0.3301\n",
      "Epoch: 087, Loss: 0.1089, Train: 0.3065, Val: 0.3312\n",
      "Epoch: 088, Loss: 0.1085, Train: 0.3078, Val: 0.3324\n",
      "Epoch: 089, Loss: 0.1085, Train: 0.3054, Val: 0.3309\n",
      "Epoch: 090, Loss: 0.1081, Train: 0.3038, Val: 0.3302\n",
      "Epoch: 091, Loss: 0.1080, Train: 0.3055, Val: 0.3318\n",
      "Epoch: 092, Loss: 0.1076, Train: 0.3069, Val: 0.3331\n",
      "Epoch: 093, Loss: 0.1075, Train: 0.3044, Val: 0.3318\n",
      "Epoch: 094, Loss: 0.1072, Train: 0.3028, Val: 0.3310\n",
      "Epoch: 095, Loss: 0.1070, Train: 0.3045, Val: 0.3323\n",
      "Epoch: 096, Loss: 0.1067, Train: 0.3047, Val: 0.3327\n",
      "Epoch: 097, Loss: 0.1065, Train: 0.3021, Val: 0.3313\n",
      "Epoch: 098, Loss: 0.1062, Train: 0.3019, Val: 0.3315\n",
      "Epoch: 099, Loss: 0.1060, Train: 0.3036, Val: 0.3331\n",
      "Epoch: 100, Loss: 0.1057, Train: 0.3030, Val: 0.3331\n",
      "Epoch: 101, Loss: 0.1055, Train: 0.3014, Val: 0.3323\n",
      "Epoch: 102, Loss: 0.1053, Train: 0.3017, Val: 0.3326\n",
      "Epoch: 103, Loss: 0.1051, Train: 0.3028, Val: 0.3335\n",
      "Epoch: 104, Loss: 0.1050, Train: 0.3016, Val: 0.3326\n",
      "Epoch: 105, Loss: 0.1047, Train: 0.3003, Val: 0.3317\n",
      "Epoch: 106, Loss: 0.1046, Train: 0.3011, Val: 0.3322\n",
      "Epoch: 107, Loss: 0.1044, Train: 0.3015, Val: 0.3325\n",
      "Epoch: 108, Loss: 0.1042, Train: 0.3001, Val: 0.3315\n",
      "Epoch: 109, Loss: 0.1040, Train: 0.2998, Val: 0.3313\n",
      "Epoch: 110, Loss: 0.1038, Train: 0.3008, Val: 0.3318\n",
      "Epoch: 111, Loss: 0.1036, Train: 0.3003, Val: 0.3313\n",
      "Epoch: 112, Loss: 0.1034, Train: 0.2990, Val: 0.3302\n",
      "Epoch: 113, Loss: 0.1033, Train: 0.2991, Val: 0.3299\n",
      "Epoch: 114, Loss: 0.1031, Train: 0.2996, Val: 0.3299\n",
      "Epoch: 115, Loss: 0.1029, Train: 0.2986, Val: 0.3288\n",
      "Epoch: 116, Loss: 0.1027, Train: 0.2978, Val: 0.3280\n",
      "Epoch: 117, Loss: 0.1026, Train: 0.2981, Val: 0.3280\n",
      "Epoch: 118, Loss: 0.1024, Train: 0.2982, Val: 0.3278\n",
      "Epoch: 119, Loss: 0.1022, Train: 0.2973, Val: 0.3268\n",
      "Epoch: 120, Loss: 0.1020, Train: 0.2968, Val: 0.3262\n",
      "Epoch: 121, Loss: 0.1019, Train: 0.2972, Val: 0.3261\n",
      "Epoch: 122, Loss: 0.1017, Train: 0.2967, Val: 0.3255\n",
      "Epoch: 123, Loss: 0.1015, Train: 0.2957, Val: 0.3245\n",
      "Epoch: 124, Loss: 0.1013, Train: 0.2954, Val: 0.3240\n",
      "Epoch: 125, Loss: 0.1011, Train: 0.2956, Val: 0.3238\n",
      "Epoch: 126, Loss: 0.1010, Train: 0.2952, Val: 0.3232\n",
      "Epoch: 127, Loss: 0.1008, Train: 0.2944, Val: 0.3225\n",
      "Epoch: 128, Loss: 0.1006, Train: 0.2945, Val: 0.3223\n",
      "Epoch: 129, Loss: 0.1004, Train: 0.2946, Val: 0.3221\n",
      "Epoch: 130, Loss: 0.1003, Train: 0.2940, Val: 0.3215\n",
      "Epoch: 131, Loss: 0.1001, Train: 0.2936, Val: 0.3209\n",
      "Epoch: 132, Loss: 0.1000, Train: 0.2938, Val: 0.3208\n",
      "Epoch: 133, Loss: 0.0998, Train: 0.2935, Val: 0.3204\n",
      "Epoch: 134, Loss: 0.0996, Train: 0.2929, Val: 0.3197\n",
      "Epoch: 135, Loss: 0.0995, Train: 0.2929, Val: 0.3195\n",
      "Epoch: 136, Loss: 0.0993, Train: 0.2930, Val: 0.3193\n",
      "Epoch: 137, Loss: 0.0992, Train: 0.2926, Val: 0.3188\n",
      "Epoch: 138, Loss: 0.0991, Train: 0.2923, Val: 0.3185\n",
      "Epoch: 139, Loss: 0.0989, Train: 0.2924, Val: 0.3183\n",
      "Epoch: 140, Loss: 0.0988, Train: 0.2921, Val: 0.3179\n",
      "Epoch: 141, Loss: 0.0986, Train: 0.2918, Val: 0.3175\n",
      "Epoch: 142, Loss: 0.0985, Train: 0.2918, Val: 0.3173\n",
      "Epoch: 143, Loss: 0.0984, Train: 0.2916, Val: 0.3171\n",
      "Epoch: 144, Loss: 0.0982, Train: 0.2913, Val: 0.3167\n",
      "Epoch: 145, Loss: 0.0981, Train: 0.2912, Val: 0.3165\n",
      "Epoch: 146, Loss: 0.0980, Train: 0.2911, Val: 0.3162\n",
      "Epoch: 147, Loss: 0.0978, Train: 0.2908, Val: 0.3158\n",
      "Epoch: 148, Loss: 0.0977, Train: 0.2907, Val: 0.3156\n",
      "Epoch: 149, Loss: 0.0976, Train: 0.2905, Val: 0.3154\n",
      "Epoch: 150, Loss: 0.0974, Train: 0.2903, Val: 0.3151\n",
      "Epoch: 151, Loss: 0.0973, Train: 0.2901, Val: 0.3148\n",
      "Epoch: 152, Loss: 0.0972, Train: 0.2900, Val: 0.3145\n",
      "Epoch: 153, Loss: 0.0970, Train: 0.2897, Val: 0.3141\n",
      "Epoch: 154, Loss: 0.0969, Train: 0.2896, Val: 0.3139\n",
      "Epoch: 155, Loss: 0.0968, Train: 0.2893, Val: 0.3134\n",
      "Epoch: 156, Loss: 0.0966, Train: 0.2892, Val: 0.3131\n",
      "Epoch: 157, Loss: 0.0965, Train: 0.2889, Val: 0.3127\n",
      "Epoch: 158, Loss: 0.0964, Train: 0.2887, Val: 0.3124\n",
      "Epoch: 159, Loss: 0.0962, Train: 0.2885, Val: 0.3119\n",
      "Epoch: 160, Loss: 0.0961, Train: 0.2884, Val: 0.3116\n",
      "Epoch: 161, Loss: 0.0960, Train: 0.2882, Val: 0.3112\n",
      "Epoch: 162, Loss: 0.0958, Train: 0.2880, Val: 0.3108\n",
      "Epoch: 163, Loss: 0.0957, Train: 0.2879, Val: 0.3105\n",
      "Epoch: 164, Loss: 0.0956, Train: 0.2877, Val: 0.3101\n",
      "Epoch: 165, Loss: 0.0954, Train: 0.2875, Val: 0.3097\n",
      "Epoch: 166, Loss: 0.0953, Train: 0.2875, Val: 0.3093\n",
      "Epoch: 167, Loss: 0.0952, Train: 0.2872, Val: 0.3088\n",
      "Epoch: 168, Loss: 0.0951, Train: 0.2873, Val: 0.3087\n",
      "Epoch: 169, Loss: 0.0949, Train: 0.2868, Val: 0.3081\n",
      "Epoch: 170, Loss: 0.0948, Train: 0.2869, Val: 0.3080\n",
      "Epoch: 171, Loss: 0.0947, Train: 0.2866, Val: 0.3075\n",
      "Epoch: 172, Loss: 0.0946, Train: 0.2864, Val: 0.3071\n",
      "Epoch: 173, Loss: 0.0944, Train: 0.2864, Val: 0.3069\n",
      "Epoch: 174, Loss: 0.0943, Train: 0.2861, Val: 0.3064\n",
      "Epoch: 175, Loss: 0.0942, Train: 0.2860, Val: 0.3061\n",
      "Epoch: 176, Loss: 0.0941, Train: 0.2860, Val: 0.3060\n",
      "Epoch: 177, Loss: 0.0939, Train: 0.2855, Val: 0.3055\n",
      "Epoch: 178, Loss: 0.0938, Train: 0.2856, Val: 0.3053\n",
      "Epoch: 179, Loss: 0.0937, Train: 0.2853, Val: 0.3049\n",
      "Epoch: 180, Loss: 0.0936, Train: 0.2851, Val: 0.3045\n",
      "Epoch: 181, Loss: 0.0935, Train: 0.2851, Val: 0.3044\n",
      "Epoch: 182, Loss: 0.0933, Train: 0.2849, Val: 0.3041\n",
      "Epoch: 183, Loss: 0.0932, Train: 0.2846, Val: 0.3038\n",
      "Epoch: 184, Loss: 0.0931, Train: 0.2847, Val: 0.3037\n",
      "Epoch: 185, Loss: 0.0930, Train: 0.2842, Val: 0.3031\n",
      "Epoch: 186, Loss: 0.0929, Train: 0.2842, Val: 0.3029\n",
      "Epoch: 187, Loss: 0.0927, Train: 0.2840, Val: 0.3026\n",
      "Epoch: 188, Loss: 0.0926, Train: 0.2836, Val: 0.3022\n",
      "Epoch: 189, Loss: 0.0925, Train: 0.2838, Val: 0.3022\n",
      "Epoch: 190, Loss: 0.0924, Train: 0.2832, Val: 0.3016\n",
      "Epoch: 191, Loss: 0.0922, Train: 0.2835, Val: 0.3016\n",
      "Epoch: 192, Loss: 0.0921, Train: 0.2831, Val: 0.3012\n",
      "Epoch: 193, Loss: 0.0920, Train: 0.2828, Val: 0.3008\n",
      "Epoch: 194, Loss: 0.0919, Train: 0.2830, Val: 0.3008\n",
      "Epoch: 195, Loss: 0.0917, Train: 0.2825, Val: 0.3003\n",
      "Epoch: 196, Loss: 0.0916, Train: 0.2825, Val: 0.3002\n",
      "Epoch: 197, Loss: 0.0915, Train: 0.2824, Val: 0.3000\n",
      "Epoch: 198, Loss: 0.0914, Train: 0.2820, Val: 0.2996\n",
      "Epoch: 199, Loss: 0.0913, Train: 0.2820, Val: 0.2994\n",
      "Epoch: 200, Loss: 0.0911, Train: 0.2817, Val: 0.2991\n",
      "Epoch: 201, Loss: 0.0910, Train: 0.2816, Val: 0.2989\n",
      "Epoch: 202, Loss: 0.0909, Train: 0.2814, Val: 0.2987\n",
      "Epoch: 203, Loss: 0.0908, Train: 0.2813, Val: 0.2985\n",
      "Epoch: 204, Loss: 0.0906, Train: 0.2812, Val: 0.2983\n",
      "Epoch: 205, Loss: 0.0905, Train: 0.2809, Val: 0.2980\n",
      "Epoch: 206, Loss: 0.0904, Train: 0.2809, Val: 0.2978\n",
      "Epoch: 207, Loss: 0.0903, Train: 0.2805, Val: 0.2975\n",
      "Epoch: 208, Loss: 0.0901, Train: 0.2805, Val: 0.2974\n",
      "Epoch: 209, Loss: 0.0900, Train: 0.2804, Val: 0.2972\n",
      "Epoch: 210, Loss: 0.0899, Train: 0.2801, Val: 0.2970\n",
      "Epoch: 211, Loss: 0.0897, Train: 0.2801, Val: 0.2969\n",
      "Epoch: 212, Loss: 0.0896, Train: 0.2797, Val: 0.2965\n",
      "Epoch: 213, Loss: 0.0895, Train: 0.2797, Val: 0.2964\n",
      "Epoch: 214, Loss: 0.0894, Train: 0.2793, Val: 0.2960\n",
      "Epoch: 215, Loss: 0.0892, Train: 0.2795, Val: 0.2961\n",
      "Epoch: 216, Loss: 0.0891, Train: 0.2790, Val: 0.2956\n",
      "Epoch: 217, Loss: 0.0890, Train: 0.2794, Val: 0.2959\n",
      "Epoch: 218, Loss: 0.0889, Train: 0.2784, Val: 0.2951\n",
      "Epoch: 219, Loss: 0.0887, Train: 0.2795, Val: 0.2958\n",
      "Epoch: 220, Loss: 0.0886, Train: 0.2778, Val: 0.2946\n",
      "Epoch: 221, Loss: 0.0885, Train: 0.2794, Val: 0.2957\n",
      "Epoch: 222, Loss: 0.0884, Train: 0.2773, Val: 0.2941\n",
      "Epoch: 223, Loss: 0.0883, Train: 0.2793, Val: 0.2955\n",
      "Epoch: 224, Loss: 0.0882, Train: 0.2764, Val: 0.2933\n",
      "Epoch: 225, Loss: 0.0881, Train: 0.2807, Val: 0.2961\n",
      "Epoch: 226, Loss: 0.0883, Train: 0.2748, Val: 0.2923\n",
      "Epoch: 227, Loss: 0.0887, Train: 0.2882, Val: 0.3010\n",
      "Epoch: 228, Loss: 0.0908, Train: 0.2741, Val: 0.2935\n",
      "Epoch: 229, Loss: 0.0949, Train: 0.3226, Val: 0.3242\n",
      "Epoch: 230, Loss: 0.1090, Train: 0.2789, Val: 0.2982\n",
      "Epoch: 231, Loss: 0.1174, Train: 0.3598, Val: 0.3528\n",
      "Epoch: 232, Loss: 0.1325, Train: 0.2867, Val: 0.3065\n",
      "Epoch: 233, Loss: 0.0952, Train: 0.2808, Val: 0.3026\n",
      "Epoch: 234, Loss: 0.1124, Train: 0.3582, Val: 0.3523\n",
      "Epoch: 235, Loss: 0.1313, Train: 0.2819, Val: 0.2987\n",
      "Epoch: 236, Loss: 0.0891, Train: 0.2872, Val: 0.3040\n",
      "Epoch: 237, Loss: 0.1273, Train: 0.3610, Val: 0.3609\n",
      "Epoch: 238, Loss: 0.1325, Train: 0.3368, Val: 0.3508\n",
      "Epoch: 239, Loss: 0.1155, Train: 0.3140, Val: 0.3366\n",
      "Epoch: 240, Loss: 0.1266, Train: 0.3157, Val: 0.3415\n",
      "Epoch: 241, Loss: 0.1206, Train: 0.3345, Val: 0.3575\n",
      "Epoch: 242, Loss: 0.1145, Train: 0.3493, Val: 0.3678\n",
      "Epoch: 243, Loss: 0.1253, Train: 0.3137, Val: 0.3415\n",
      "Epoch: 244, Loss: 0.1061, Train: 0.3059, Val: 0.3318\n",
      "Epoch: 245, Loss: 0.1219, Train: 0.3044, Val: 0.3292\n",
      "Epoch: 246, Loss: 0.1092, Train: 0.3175, Val: 0.3375\n",
      "Epoch: 247, Loss: 0.1093, Train: 0.3212, Val: 0.3367\n",
      "Epoch: 248, Loss: 0.1105, Train: 0.2938, Val: 0.3127\n",
      "Epoch: 249, Loss: 0.0962, Train: 0.2882, Val: 0.3057\n",
      "Epoch: 250, Loss: 0.1080, Train: 0.2906, Val: 0.3065\n",
      "Epoch: 251, Loss: 0.0906, Train: 0.3127, Val: 0.3200\n",
      "Epoch: 252, Loss: 0.1010, Train: 0.2866, Val: 0.2994\n",
      "Epoch: 253, Loss: 0.0886, Train: 0.2800, Val: 0.2956\n",
      "Epoch: 254, Loss: 0.1007, Train: 0.2864, Val: 0.2948\n",
      "Epoch: 255, Loss: 0.0889, Train: 0.3023, Val: 0.3032\n",
      "Epoch: 256, Loss: 0.0965, Train: 0.2764, Val: 0.2880\n",
      "Epoch: 257, Loss: 0.0898, Train: 0.2748, Val: 0.2876\n",
      "Epoch: 258, Loss: 0.0921, Train: 0.2974, Val: 0.2967\n",
      "Epoch: 259, Loss: 0.0950, Train: 0.2812, Val: 0.2869\n",
      "Epoch: 260, Loss: 0.0884, Train: 0.2733, Val: 0.2884\n",
      "Epoch: 261, Loss: 0.0972, Train: 0.2889, Val: 0.2907\n",
      "Epoch: 262, Loss: 0.0912, Train: 0.2853, Val: 0.2886\n",
      "Epoch: 263, Loss: 0.0897, Train: 0.2726, Val: 0.2877\n",
      "Epoch: 264, Loss: 0.0952, Train: 0.2801, Val: 0.2866\n",
      "Epoch: 265, Loss: 0.0874, Train: 0.2873, Val: 0.2908\n",
      "Epoch: 266, Loss: 0.0899, Train: 0.2727, Val: 0.2868\n",
      "Epoch: 267, Loss: 0.0896, Train: 0.2746, Val: 0.2862\n",
      "Epoch: 268, Loss: 0.0862, Train: 0.2874, Val: 0.2924\n",
      "Epoch: 269, Loss: 0.0893, Train: 0.2754, Val: 0.2873\n",
      "Epoch: 270, Loss: 0.0859, Train: 0.2741, Val: 0.2884\n",
      "Epoch: 271, Loss: 0.0881, Train: 0.2822, Val: 0.2910\n",
      "Epoch: 272, Loss: 0.0869, Train: 0.2814, Val: 0.2910\n",
      "Epoch: 273, Loss: 0.0866, Train: 0.2744, Val: 0.2895\n",
      "Epoch: 274, Loss: 0.0874, Train: 0.2763, Val: 0.2896\n",
      "Epoch: 275, Loss: 0.0856, Train: 0.2832, Val: 0.2926\n",
      "Epoch: 276, Loss: 0.0871, Train: 0.2758, Val: 0.2895\n",
      "Epoch: 277, Loss: 0.0854, Train: 0.2739, Val: 0.2892\n",
      "Epoch: 278, Loss: 0.0864, Train: 0.2790, Val: 0.2906\n",
      "Epoch: 279, Loss: 0.0856, Train: 0.2781, Val: 0.2902\n",
      "Epoch: 280, Loss: 0.0854, Train: 0.2726, Val: 0.2887\n",
      "Epoch: 281, Loss: 0.0858, Train: 0.2743, Val: 0.2886\n",
      "Epoch: 282, Loss: 0.0846, Train: 0.2781, Val: 0.2899\n",
      "Epoch: 283, Loss: 0.0853, Train: 0.2722, Val: 0.2875\n",
      "Epoch: 284, Loss: 0.0846, Train: 0.2715, Val: 0.2873\n",
      "Epoch: 285, Loss: 0.0846, Train: 0.2762, Val: 0.2887\n",
      "Epoch: 286, Loss: 0.0848, Train: 0.2724, Val: 0.2873\n",
      "Epoch: 287, Loss: 0.0841, Train: 0.2702, Val: 0.2867\n",
      "Epoch: 288, Loss: 0.0845, Train: 0.2740, Val: 0.2877\n",
      "Epoch: 289, Loss: 0.0841, Train: 0.2727, Val: 0.2872\n",
      "Epoch: 290, Loss: 0.0839, Train: 0.2696, Val: 0.2864\n",
      "Epoch: 291, Loss: 0.0842, Train: 0.2725, Val: 0.2872\n",
      "Epoch: 292, Loss: 0.0837, Train: 0.2728, Val: 0.2874\n",
      "Epoch: 293, Loss: 0.0836, Train: 0.2695, Val: 0.2866\n",
      "Epoch: 294, Loss: 0.0837, Train: 0.2716, Val: 0.2872\n",
      "Epoch: 295, Loss: 0.0833, Train: 0.2728, Val: 0.2877\n",
      "Epoch: 296, Loss: 0.0833, Train: 0.2697, Val: 0.2867\n",
      "Epoch: 297, Loss: 0.0833, Train: 0.2710, Val: 0.2873\n",
      "Epoch: 298, Loss: 0.0829, Train: 0.2726, Val: 0.2879\n",
      "Epoch: 299, Loss: 0.0830, Train: 0.2699, Val: 0.2872\n",
      "Epoch: 300, Loss: 0.0828, Train: 0.2706, Val: 0.2874\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 301):\n",
    "    train_data = train_data.to(device)\n",
    "    loss = train()\n",
    "    train_rmse = test(train_data)\n",
    "    val_rmse = test(val_data)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n",
    "          f'Val: {val_rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.3099\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_data = test_data.to(device)\n",
    "    pred = model(test_data.x_dict, test_data.edge_index_dict,\n",
    "                 test_data['source', 'target'].edge_label_index)\n",
    "    pred = pred.clamp(min=0, max=1)\n",
    "    target = test_data['source', 'target'].edge_label.float()\n",
    "    rmse = F.mse_loss(pred, target).sqrt()\n",
    "    print(f'Test RMSE: {rmse:.4f}')\n",
    "\n",
    "sour = test_data['source', 'target'].edge_label_index[0].cpu().numpy()\n",
    "tar = test_data['source', 'target'].edge_label_index[1].cpu().numpy()\n",
    "pred = pred.cpu().numpy()\n",
    "target = target.cpu().numpy()\n",
    "\n",
    "res=pd.DataFrame({'source': sour, 'target': tar, 'pred': pred, 'compare': target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a new column if pred is greater or equal than 0.5 then 1 else 0.5\n",
    "res['weight'] = np.where(res['pred']>=0.5, 1, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>compare</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "      <td>0.785356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1257</td>\n",
       "      <td>1258</td>\n",
       "      <td>0.474498</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>473</td>\n",
       "      <td>114</td>\n",
       "      <td>0.672265</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>258</td>\n",
       "      <td>259</td>\n",
       "      <td>0.920634</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>508</td>\n",
       "      <td>0.618540</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source  target      pred  compare  weight\n",
       "0     196     197  0.785356      1.0     1.0\n",
       "1    1257    1258  0.474498      1.0     0.5\n",
       "2     473     114  0.672265      0.5     1.0\n",
       "3     258     259  0.920634      1.0     1.0\n",
       "4     917     508  0.618540      0.5     1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.546742209631728\n",
      "Number of correct predictions: 193\n"
     ]
    }
   ],
   "source": [
    "#compare column rating_1 with target and if they are equal add up\n",
    "cont=0\n",
    "for i in res.itertuples():\n",
    "    if i.compare == i.weight:\n",
    "        cont+=1\n",
    "\n",
    "#Calculate the accuracy\n",
    "accuracy = cont/len(res)\n",
    "print('Accuracy:', accuracy)\n",
    "print('Number of correct predictions:', cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try with different graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read a new csv file\n",
    "file_test = cwd + '/points_10.csv'\n",
    "df_test=pd.read_csv(file_test, sep=',')\n",
    "\n",
    "#Round the values of the dataset to 4 decimal places\n",
    "df_test = df_test.round(4)\n",
    "\n",
    "#Add a column to use as index from 0 to the length of the dataset\n",
    "df_test['n_label'] = range(0, len(df_test))\n",
    "\n",
    "#delete the column p_label\n",
    "df_test = df_test.drop('p_label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_10=HeteroData()\n",
    "\n",
    "nodes_s=df_test['n_label'].values\n",
    "nodes_t=df_test['n_label'].values\n",
    "\n",
    "data_10['source'].node_id = torch.tensor(nodes_s, dtype=torch.long)\n",
    "data_10['target'].node_id = torch.tensor(nodes_t, dtype=torch.long)\n",
    "\n",
    "data_10['source'].x = Tensor(df_test[['x', 'y', 'z']].values)\n",
    "data_10['target'].x = Tensor(df_test[['x', 'y', 'z']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_test_path = cwd + '/grap_10.csv'\n",
    "\n",
    "# Importing the dataset\n",
    "df_test_edge = pd.read_csv(edge_test_path)\n",
    "\n",
    "edge_index_test = torch.tensor([df_test_edge['Source'], df_test_edge['Target']], dtype=torch.long)\n",
    "\n",
    "data_10['source', 'weight', 'target'].edge_index = edge_index_test\n",
    "\n",
    "weight_test = torch.from_numpy(df_test_edge['weight'].values).to(torch.float)\n",
    "\n",
    "data_10['source', 'weight', 'target'].edge_label=weight_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_10= T.ToUndirected()(data_10)\n",
    "del data_10['target', 'rev_weight', 'source'].edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  source={\n",
       "    node_id=[100],\n",
       "    x=[100, 3],\n",
       "  },\n",
       "  target={\n",
       "    node_id=[100],\n",
       "    x=[100, 3],\n",
       "  },\n",
       "  (source, weight, target)={\n",
       "    edge_index=[2, 107],\n",
       "    edge_label=[107],\n",
       "  },\n",
       "  (target, rev_weight, source)={ edge_index=[2, 107] }\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_10.validate(raise_on_error=True))\n",
    "data_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.3585\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    data_10 = data_10.to(device)\n",
    "    pred = model(data_10.x_dict, data_10.edge_index_dict,\n",
    "                 data_10['source', 'target'].edge_index)\n",
    "    pred = pred.clamp(min=0, max=1)\n",
    "    target = data_10['source', 'target'].edge_label.float()\n",
    "    rmse = F.mse_loss(pred, target).sqrt()\n",
    "    print(f'Test RMSE: {rmse:.4f}')\n",
    "\n",
    "sour = data_10['source', 'target'].edge_index[0].cpu().numpy()\n",
    "tar = data_10['source', 'target'].edge_index[1].cpu().numpy()\n",
    "pred = pred.cpu().numpy()\n",
    "target = target.cpu().numpy()\n",
    "\n",
    "res=pd.DataFrame({'source': sour, 'target': tar, 'pred': pred, 'compare': target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6728971962616822\n",
      "Number of correct predictions: 72\n"
     ]
    }
   ],
   "source": [
    "#Add a new column if pred is greater or equal than 0.5 then 1 else 0.5\n",
    "res['weight'] = np.where(res['pred']>0.5, 1, 0.5)\n",
    "\n",
    "#compare column rating_1 with target and if they are equal add up\n",
    "cont=0\n",
    "for i in res.itertuples():\n",
    "    if i.compare == i.weight:\n",
    "        cont+=1\n",
    "\n",
    "#Calculate the accuracy\n",
    "accuracy = cont/len(res)\n",
    "print('Accuracy:', accuracy)\n",
    "print('Number of correct predictions:', cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
