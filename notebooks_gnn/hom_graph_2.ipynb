{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu121\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import Tensor\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TORCH'] = torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siguiendo el modelo de:\n",
    "https://github.com/Orbifold/pyg-link-prediction/blob/main/Pokec-Pyg-Neo4j.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "file_path = cwd + '/points_50.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "#Round the values of the dataset to 4 decimal places\n",
    "df = df.round(4)\n",
    "\n",
    "#Add a column to use as index from 0 to the length of the dataset\n",
    "df['n_label'] = range(0, len(df))\n",
    "\n",
    "#delete the column p_label\n",
    "df = df.drop('p_label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>N_side</th>\n",
       "      <th>N_layer</th>\n",
       "      <th>t_label</th>\n",
       "      <th>phi</th>\n",
       "      <th>eta</th>\n",
       "      <th>q</th>\n",
       "      <th>pt</th>\n",
       "      <th>d0</th>\n",
       "      <th>z0</th>\n",
       "      <th>n_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.1120</td>\n",
       "      <td>-9.9682</td>\n",
       "      <td>-6.3331</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>T0</td>\n",
       "      <td>-1.6049</td>\n",
       "      <td>-0.6008</td>\n",
       "      <td>-1</td>\n",
       "      <td>48.2712</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.4144</td>\n",
       "      <td>-19.8918</td>\n",
       "      <td>-12.6639</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>T0</td>\n",
       "      <td>-1.6049</td>\n",
       "      <td>-0.6008</td>\n",
       "      <td>-1</td>\n",
       "      <td>48.2712</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.6930</td>\n",
       "      <td>-29.8162</td>\n",
       "      <td>-18.9948</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>T0</td>\n",
       "      <td>-1.6049</td>\n",
       "      <td>-0.6008</td>\n",
       "      <td>-1</td>\n",
       "      <td>48.2712</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.022</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.9483</td>\n",
       "      <td>-39.7538</td>\n",
       "      <td>-25.3337</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>T0</td>\n",
       "      <td>-1.6049</td>\n",
       "      <td>-0.6008</td>\n",
       "      <td>-1</td>\n",
       "      <td>48.2712</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.022</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.1794</td>\n",
       "      <td>-49.6794</td>\n",
       "      <td>-31.6646</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>T0</td>\n",
       "      <td>-1.6049</td>\n",
       "      <td>-0.6008</td>\n",
       "      <td>-1</td>\n",
       "      <td>48.2712</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.022</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x        y        z  N_side  N_layer t_label     phi     eta  q  \\\n",
       "0 -0.1120  -9.9682  -6.3331       8        1      T0 -1.6049 -0.6008 -1   \n",
       "1 -0.4144 -19.8918 -12.6639       8        2      T0 -1.6049 -0.6008 -1   \n",
       "2 -0.6930 -29.8162 -18.9948       8        3      T0 -1.6049 -0.6008 -1   \n",
       "3 -0.9483 -39.7538 -25.3337       8        4      T0 -1.6049 -0.6008 -1   \n",
       "4 -1.1794 -49.6794 -31.6646       8        5      T0 -1.6049 -0.6008 -1   \n",
       "\n",
       "        pt      d0     z0  n_label  \n",
       "0  48.2712  0.2156  0.022        0  \n",
       "1  48.2712  0.2156  0.022        1  \n",
       "2  48.2712  0.2156  0.022        2  \n",
       "3  48.2712  0.2156  0.022        3  \n",
       "4  48.2712  0.2156  0.022        4  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pytorch geometric data object\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "data=Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add nodes to the data object from n_label column\n",
    "data.x = torch.tensor(df[['x','y','z','phi','eta','pt','d0','z0']].values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_path = cwd + '/grap_50.csv'\n",
    "\n",
    "# Importing the dataset\n",
    "df_edge = pd.read_csv(edge_path)\n",
    "\n",
    "#Add edges to the data object\n",
    "data.edge_index = torch.tensor(df_edge[['Source','Target']].values, dtype=torch.long).t().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[500, 8], edge_index=[2, 692])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.validate(raise_on_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.edge_attr = torch.tensor(df_edge['weight'], dtype=torch.float).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "data = T.ToUndirected()(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[500, 8], edge_index=[2, 1384], edge_attr=[1384, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_node_masks(d):\n",
    "        print(\"Creating classification masks\")\n",
    "        amount = len(d.x)\n",
    "        # actually the index to the nodes\n",
    "        nums = np.arange(amount)\n",
    "        np.random.shuffle(nums)\n",
    "\n",
    "        train_size = int(amount * 0.7)\n",
    "        test_size = int(amount * 0.85) - train_size\n",
    "        val_size = amount - train_size - test_size\n",
    "\n",
    "        train_set = nums[0:train_size]\n",
    "        test_set = nums[train_size:train_size + test_size]\n",
    "        val_set = nums[train_size + test_size:]\n",
    "\n",
    "        assert len(train_set) + len(test_set) + len(val_set) == amount, \"The split should be coherent.\"\n",
    "        \n",
    "        train_mask = torch.zeros(amount, dtype = torch.long, device = device)\n",
    "        for i in train_set:\n",
    "            train_mask[i] = 1.\n",
    "\n",
    "        test_mask = torch.zeros(amount, dtype = torch.long, device = device)\n",
    "        for i in test_set:\n",
    "            test_mask[i] = 1.\n",
    "\n",
    "        val_mask = torch.zeros(amount, dtype = torch.long, device = device)\n",
    "        for i in val_set:\n",
    "            val_mask[i] = 1.\n",
    "\n",
    "        d.train_mask = train_mask\n",
    "        d.test_mask = test_mask\n",
    "        d.val_mask = val_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating classification masks\n"
     ]
    }
   ],
   "source": [
    "create_node_masks(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[500, 8], edge_index=[2, 1384], edge_attr=[1384, 1], train_mask=[500], test_mask=[500], val_mask=[500], edge_label=[692], edge_label_index=[2, 692]),\n",
       " Data(x=[500, 8], edge_index=[2, 1384], edge_attr=[1384, 1], train_mask=[500], test_mask=[500], val_mask=[500], edge_label=[0], edge_label_index=[2, 0]),\n",
       " Data(x=[500, 8], edge_index=[2, 1384], edge_attr=[1384, 1], train_mask=[500], test_mask=[500], val_mask=[500], edge_label=[0], edge_label_index=[2, 0]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.ToUndirected(merge = True),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val = 0.0005, num_test = 0.0001, is_undirected = True, add_negative_train_samples = False),\n",
    "])\n",
    "transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the larger the batch size the faster things will be\n",
    "batch_size = 32\n",
    "\n",
    "# define batch loaders for the three sets\n",
    "train_loader = NeighborLoader(data, num_neighbors = [10] * 2, shuffle = True, input_nodes = data.train_mask, batch_size = batch_size)\n",
    "val_loader = NeighborLoader(data, num_neighbors = [10] * 2, input_nodes = data.val_mask, batch_size = batch_size)\n",
    "test_loader = NeighborLoader(data, num_neighbors = [10] * 2, input_nodes = data.test_mask, batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        # chaining two convolutions with a standard relu activation\n",
    "\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        # cosine similarity\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim = -1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple = False).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(data.num_features, 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = 0.01)\n",
    "# BCELoss creates a criterion that measures the Binary Cross Entropy between the target and the output.\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): GCNConv(8, 128)\n",
       "  (conv2): GCNConv(128, 64)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \"\"\"\n",
    "    Single epoch model training in batches.\n",
    "    :return: total loss for the epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_examples = total_loss = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to(device)\n",
    "        batch_size = batch.batch_size\n",
    "        z = model.encode(batch.x, batch.edge_index)\n",
    "        neg_edge_index = negative_sampling(edge_index = batch.edge_index, num_nodes = batch.num_nodes, num_neg_samples = None, method = 'sparse')\n",
    "        edge_label_index = torch.cat([batch.edge_index, neg_edge_index], dim = -1, )\n",
    "        edge_label = torch.cat([torch.ones(batch.edge_index.size(1)), torch.zeros(neg_edge_index.size(1))], dim = 0).to(device)\n",
    "        out = model.decode(z, edge_label_index).view(-1)\n",
    "        # loss = criterion(out[:batch_size], edge_label[:batch_size])\n",
    "        loss = criterion(out, edge_label)\n",
    "        # standard torch mechanics here\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_examples += batch_size\n",
    "        total_loss += float(loss) * batch_size\n",
    "    return total_loss / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    \"\"\"\n",
    "    Evalutes the model on the test set.\n",
    "    :param loader: the batch loader\n",
    "    :return: a score\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    scores = []\n",
    "    threshold = torch.tensor([0.7]).to(device)\n",
    "    for batch in tqdm(loader):\n",
    "        batch.to(device)\n",
    "        z = model.encode(batch.x, batch.edge_index)\n",
    "        out = model.decode(z, batch.edge_index).view(-1).sigmoid()\n",
    "        pred = (out > threshold).float() * 1\n",
    "        score = f1_score(np.ones(batch.edge_index.size(1)), pred.cpu().numpy())\n",
    "        scores.append(score)\n",
    "    return np.average(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(max = 50, threshold = 0.99):\n",
    "    \"\"\"\n",
    "    Creates predictions for the specified run.\n",
    "    :param run_id: model id\n",
    "    :param max: the maximum amount of predictions to output\n",
    "    \"\"\"\n",
    "    pred_edges = []\n",
    "\n",
    "    loader = NeighborLoader(data, num_neighbors = [10] * 2, shuffle = True, input_nodes = None, batch_size = batch_size)\n",
    "    threshold_tensor = torch.tensor([threshold]).to(device)\n",
    "    for batch in tqdm(loader):\n",
    "        batch.to(device)\n",
    "        z = model.encode(batch.x, batch.edge_index)\n",
    "        # collecting negative edge tuples ensure that the decode are actual non-existing edges\n",
    "        neg_edge_index = negative_sampling(edge_index = batch.edge_index, num_nodes = None, num_neg_samples = None, method = 'sparse')\n",
    "        out = model.decode(z, neg_edge_index).view(-1).sigmoid()\n",
    "        pred = ((out > threshold_tensor).float() * 1).cpu().numpy()\n",
    "        found = np.argwhere(pred == 1)\n",
    "        if found.size > 0:\n",
    "            edge_tuples = neg_edge_index.t().cpu().numpy()\n",
    "            select_index = found.reshape(1, found.size)[0]\n",
    "            edges = edge_tuples[select_index]\n",
    "            pred_edges += edges.tolist()\n",
    "            if len(pred_edges) >= max:\n",
    "                break\n",
    "    return pd.DataFrame.from_dict([{'source': a, 'target': b} for a,b in pred_edges])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    \"\"\"\n",
    "        Run the training and makes predictions.\n",
    "    \"\"\"\n",
    "    run_id = int(datetime.timestamp(datetime.now()))\n",
    "    start_time = datetime.now()\n",
    "    epochs = 10\n",
    "    #with trange(epochs + 1) as t:\n",
    "    for epoch in range(epochs):\n",
    "        try:\n",
    "            #t.set_description('Epoch %i/%i train' % (epoch, epochs))\n",
    "            loss = train()\n",
    "            #t.set_description('Epoch %i/%i test' % (epoch, epochs))\n",
    "            val_acc = test(test_loader)\n",
    "            #t.set_postfix(loss = loss, accuracy = val_acc)\n",
    "            print(f\"Epoch: {epoch:03d}, Loss: {loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "    #torch.save(model.state_dict(), f\"model_{run_id}\")\n",
    "    time_elapsed = datetime.now() - start_time\n",
    "    print(\"Creating predictions\")\n",
    "    print(f\"\\nRun {run_id}:\")\n",
    "    print(f\"\\tEpochs: {epoch}\")\n",
    "    print(f\"\\tTime: {time_elapsed}\")\n",
    "    print(f\"\\tAccuracy: {val_acc * 100:.01f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 28.93it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 100.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 176.8665, Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 70.47it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 178.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 11.6302, Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 94.39it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 182.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss: 3.0353, Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 101.40it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 160.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Loss: 1.0609, Acc: 0.9931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 91.39it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 177.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Loss: 0.8388, Acc: 0.9575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 52.92it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 173.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Loss: 0.6941, Acc: 0.9575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 95.59it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 166.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Loss: 0.7460, Acc: 0.9575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 100.35it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 147.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Loss: 0.6984, Acc: 0.9897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 84.81it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 145.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008, Loss: 0.7127, Acc: 0.8745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 62.19it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 153.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Loss: 0.6803, Acc: 0.9764\n",
      "Creating predictions\n",
      "\n",
      "Run 1717694849:\n",
      "\tEpochs: 9\n",
      "\tTime: 0:00:03.491002\n",
      "\tAccuracy: 97.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   source  target\n",
      "0      10      83\n",
      "1      67      98\n",
      "2     156     157\n",
      "3       8      99\n",
      "4      28      75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds_df = predictions()\n",
    "print(preds_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrado:  156 157\n"
     ]
    }
   ],
   "source": [
    "for i in df_edge.itertuples():\n",
    "    for j in preds_df.itertuples():\n",
    "        if i.Source == j.source and i.Target == j.target:\n",
    "            print(\"Encontrado: \", i.Source, i.Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions: 1\n"
     ]
    }
   ],
   "source": [
    "#Compare predictions with the real edges\n",
    "real_edges = df_edge[['Source', 'Target']]\n",
    "real_edges = real_edges.rename(columns={'Source': 'source', 'Target': 'target'})\n",
    "\n",
    "#Merge the two dataframes\n",
    "merged = pd.merge(preds_df, real_edges, on=['source', 'target'], how='inner')\n",
    "\n",
    "#Calculate the number of correct predictions\n",
    "correct = len(merged)\n",
    "print(f\"Correct predictions: {correct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
